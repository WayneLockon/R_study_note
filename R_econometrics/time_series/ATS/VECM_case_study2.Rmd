---
title: "VECM model"
author: "Weiheng Zhang"
date: '2022-04-25'
output: pdf_document
---

```{r, message=FALSE, warning=FALSE}
library(FinMetric)
library(tsDyn)
library(vars)
digits <- function(x, n){
    format(round(x, n), nsmall = n)
}
```



```{r}
dat <- read_stata("https://www.stata-press.com/data/r17/rdinc")
ggplot(dat) +
    geom_line(aes(x = year, y = ln_ne, color = "ln(new_england)")) +
    geom_line(aes(x = year, y = ln_se, color = "ln(southeast)")) +
    scale_color_manual(values = c("ln(new_england)" = "steelblue", "ln(southeast)" = "darkred")) +
    theme(legend.position = "bottom") +
    scale_x_continuous(breaks = seq(1950, 2000, 10)) +
    labs(y = "")
```
The graph indicates a differential between the two series that shrinks between 1960 and about 1980 and then grows until it stabilizes around 1990. We next estimate the parameters of a bivariate VECM with one cointegrating relationship.

```{r}
vec1 <- VECM(dat[, c("ln_ne", "ln_se")], lag = 1, estim = "ML")
# STATA use ML to estimate
summary(vec1)
```

Rather than being covariance stationary, many economic time series appear to be "first-difference stationary". This means that the level of a time series is not stationary but its first difference is. This kind of series denotes as $I(1)$ processes, while covariance stationary series denotes as $I(0)$. In general, a process whose d-th difference is stationary is an integrated process of order d, or $I(d)$.

## Multivariate VECM specification

Consider a VAR with p lags:

$$y_t = v + A_1 y_{t - 1} + \cdots + A_p y_{t - p} + \varepsilon_t$$

where $y_t$ is a $1\times k$ vector.

We can construct following VECM model:

$$\begin{aligned}
\Delta y_t &= v + (\sum_1^p A_j - I_k) y_{t - 1} + \sum_1^{p - 1} (-\sum_{j = i + 1}^p A_j) \Delta y_{t - i} + \varepsilon_t \\
\Delta y_t &= v + \Pi y_{t - 1} + \sum_{i = 1}^{p - 1} \Gamma_i\Delta y_{t - i} + \varepsilon_t
\end{aligned}$$

if p = 2, it will be:

$$y_t - y_{t - 1} = v + (A_1 + A_2 - I) y_{t - 1} + (-A_2)\Delta y_{t - 1} + \varepsilon_t$$


In general we can contain time trend in VECM model:

$$\Delta y_t = \alpha(\beta y_{t - 1} + \mu + \rho t) + \sum_{i = 1}^{p - 1} \Gamma_i\Delta y_{t - i} + \gamma + \tau t + \varepsilon_t$$

* Case 1: Unrestricted trend
    * If no restrictions are placed on the trend parameters, the equation implies that there are quadratic trends in the levels of the variables and that the cointegrating equations are stationary around time trends (trend stationary).
* Case 2: Restricted trend ($\tau = 0$)
    * We assume that the trends in the levels of the data are linear but not quadratic.
* Case 3: Unrestricted constant ($\tau = 0$ and $\rho = 0$)
    * We restrict the cointegrating equation to be stationary around constant means. Because $\gamma$ is not restricted to zero, this specification still puts a linear time trend int he levels of the data.
* Case 4: Restricted constant ($\tau = 0$, $\rho = 0$ and $\gamma = 0$)
    * We assume there are no linear time trends int he levels of the data. The cointegrating equations to be stationary around a constant mean, but it allows no other trends and constant terms.
* Case 5: No trend: ($\tau = 0$, $\rho = 0$, $\gamma = 0$ and $\mu = 0$)
    * It assumes that the equations are stationary with means of zero and that the differences and the levels of the data have means of zero.
    
```{r}
dat <- read_stata("https://www.stata-press.com/data/r17/txhprice")
dat$t <- seq(as.Date("1990-01-01"), as.Date("2003-12-01"), by = "month")
ggplot(dat) +
    geom_line(aes(x = t, y = austin, color = "austin")) +
    geom_line(aes(x = t, y = dallas, color = "dallas")) +
    geom_line(aes(x = t, y = houston, color = "houston")) +
    geom_line(aes(x = t, y = sa, color = "san antonio")) +
    scale_color_manual(values = c("austin" = "steelblue", 
                                  "dallas" = "darkred",
                                  "houston" = "darkgreen",
                                  "san antonio" = "orange")) +
    theme(legend.position = "bottom") +
    labs(y = "") +
    scale_x_date(breaks = scales::breaks_width("2 year"), date_labels = "%Y-%m")
```

Here, we focus on the housing prices in Dallas and Houston. 

```{r}
y <- dat[, c("dallas", "houston")]
VARselect(y)
```

Here we will consider 2 lags based on HQ (Hannanâ€“Quinn information criterion) and SC (Schwarz Bayesian information criterion).

```{r}
urca::ca.jo(y, type = "eigen", K = 2, ecdet = "const") %>% 
    summary() # indicate it is a I(1) process

vec1 <- VECM(y, lag = 1, estim = "ML")
summary(vec1)


irf_vecm <- irf(vec1, boot = T, runs = 100, n.ahead = 40)
# Dallas -> Houston
data_plot <- data.frame(irf = irf_vecm$irf$dallas[, 2],lower = irf_vecm$Lower$dallas[, 2], upper = irf_vecm$Upper$dallas[, 2], t = 0:40)
ggplot(data_plot, aes(x = t, y = irf, ymin = lower, ymax = upper)) +
    geom_line(color = "steelblue") +
    geom_ribbon(alpha = .2) +
    geom_hline(yintercept = 0, color = "red")
```

Based on the estimation we know that

$$\Delta y_t = \hat\alpha(\hat\beta y_{t - 1} ) + \sum_{i = 1}^{p - 1} \Gamma_i\Delta y_{t - i} + \hat v + \varepsilon_t$$

$\hat \alpha = ($ `r paste(digits(vec1$coefficients[, 1], 3), sep = ", ")` $)$

$\hat \beta = ($ `r paste(digits(vec1$model.specific$beta, 3), sep = ", ")` $)$
    
$\hat v = ($ `r paste(digits(vec1$coefficients[, 2], 3), sep = ", ")` $)$
    
$\hat\Gamma =$ 

```{r}
digits(vec1$coefficients[, c(3, 4)], 3) %>% 
    knitr::kable(col.names = c("dallas", "houston"))
```

    
    
    
    
    
    
    