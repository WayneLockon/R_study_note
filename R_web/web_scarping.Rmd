---
title: "L4 Web Scraping"
author: "Wayne Zhang"
date: "3/7/2022"
output: 
  html_document: 
    toc: yes
---

# Basics

```{r}
# read html
library(xml2)
library(rvest)
library(tidyverse)

html_excerpt_raw <- '
<html> 
  <body> 
    <h1>Web scraping is cool</h1>
    <p>It involves writing code â€“ be it R or Python.</p>
    <p><a href="https://datacamp.com">DataCamp</a> 
		has courses on it.</p>
  </body> 
</html>'

# Turn the raw excerpt into an HTML document R understands
html_excerpt <- read_html(html_excerpt_raw)
html_excerpt # it is a character
xml_structure(html_excerpt) # html order
```

```{r}
list_raw_html <- "\n<html>\n  <body>\n    <ol>\n      <li>Learn HTML</li>\n      <li>Learn CSS</li>\n      <li>Learn R</li>\n      <li>Scrape everything!*</li>\n    </ol>\n    <small>*Do it responsibly!</small>\n  </body>\n</html>"

list_html <- read_html(list_raw_html)
xml_structure(list_html)
# Extract the ol node
ol_node <- list_html %>% 
	html_node('ol')
# Extract and print the nodeset of all the children of ol_node
ol_node %>%
	html_children()

hyperlink_raw_html <- "\n<html>\n  <body>\n    <h3>Helpful links</h3>\n    <ul>\n      <li><a href=\"https://wikipedia.org\">Wikipedia</a></li>\n      <li><a href=\"https://dictionary.com\">Dictionary</a></li>\n      <li><a href=\"https://duckduckgo.com\">Search Engine</a></li>\n    </ul>\n    <small>\n      Compiled with help from <a href=\"https://google.com\">Google</a>.\n    </small>\n  </body>\n</html>"

# Extract all the a nodes from the bulleted list
links <- hyperlink_raw_html %>% 
  read_html() %>%
  html_nodes('li a') # 'ul a' is also correct!
```

Extract both the domain (`href` attribute) and the link name (text node) from `links`.

```{r}
# Extract the needed values for the data frame
domain_value = links %>% html_attr("href")
name_value = links %>% html_text("text")

# Construct a data frame
link_df <- tibble(
  domain = domain_value,
  name = name_value
)

link_df
```

**Read table** in html

Extract the `"clean"` table into a data frame 


```{r}
mountains_html <-  "<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\" \"http://www.w3.org/TR/REC-html40/loose.dtd\">\n<html>\n<head><meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"></head>\n<body> \n  <table id=\"clean\">\n<tr>\n<th>Mountain</th>\n      <th>Height [m]</th>\n      <th>First ascent</th>\n      <th>Country</th>\n    </tr>\n<tr>\n<td>Mount Everest</td>\n      <td>8848</td>\n      <td>1953</td>\n      <td>Nepal, China</td>\n    </tr>\n<tr>\n<td>K2</td>\n      <td>8611</td>\n      <td>1954</td>\n      <td>Pakistan, China</td>\n    </tr>\n<tr>\n<td>Kanchenjunga</td>\n      <td>8586</td>\n      <td>1955</td>\n      <td>Nepal, India</td>\n    </tr>\n</table>\n<table id=\"dirty\">\n<tr>\n<td>Mountain </td>\n      <td>Height [m]</td>\n      <td>First ascent</td>\n      <td>Country</td>\n    </tr>\n<tr>\n<td>Mount Everest</td>\n      <td>8848</td>\n      <td>1953</td>\n    </tr>\n<tr>\n<td>K2</td>\n      <td>8611</td>\n      <td>1954</td>\n      <td>Pakistan, China</td>\n    </tr>\n<tr>\n<td>Kanchenjunga</td>\n      <td>8586</td>\n      <td>1955</td>\n      <td>Nepal, India</td>\n    </tr>\n</table>\n</body>\n</html>\n" %>% read_html()

mountains_html %>% 
    html_nodes("table#clean") %>% 
    xml_structure()

mountains <- mountains_html %>% 
    html_nodes("table#clean") %>% 
    html_table()
mountains
```

treat the first line as header and fill up missing cells.

```{r}
mountains <- mountains_html %>% 
  html_node("table#dirty") %>% 
  html_table(header = T, fill = T)
mountains
```

# CSS

```{r}
languages_raw_html <- "\n<html> \n  <body> \n    <div>Python is perfect for programming.</div>\n    <p>Still, R might be better suited for data analysis.</p>\n    <small>(And has prettier charts, too.)</small>\n  </body> \n</html>"

# Read in the HTML
languages_html <- read_html(languages_raw_html)
# Select the div and p tags and print their text
languages_html %>%
	html_nodes("div, p") %>%
	html_text()
```

